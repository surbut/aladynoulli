for (d in 1:n_diseases) {
event_time <- which(Y[i, d, ] == 1)
if (length(event_time) > 0) {
event_indices <- c(event_indices, list(c(i, d, event_time)))
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:(event_time-1))))
} else {
# If no event, consider at risk for all time points
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:Ttot)))
}
}
}
list(event_indices = do.call(rbind, event_indices),
at_risk_indices = do.call(rbind, at_risk_indices))
}
a=precompute_likelihood_indices(Y)
head(a)
dim(a)
a
length(a)
class(a)
a[[1]]
sum(y)
Y
sum(Y)
head(pi)
K = 3
N = 1000
D = 5
T = 50
num_covariates = 5
## things we will treat as fixed:
# Create time differences matrix
time_diff <- outer(seq_len(T), seq_len(T), "-")
# Store scales
length_scales_lambda <- runif(K, T / 3, T / 2)
var_scales_lambda <- runif(K, 0.8, 1.2)  # Reduced range to control the scale
length_scales_phi <- runif(K, T / 3, T / 2)
var_scales_phi <- runif(K, 0.8, 1.2)
length_scales_mu <- runif(D, T / 3, T / 2)
var_scales_mu <- runif(D, 0.8, 1.2)
## simulate mu (we will treat as fixed)
mu_d = array(NA, dim = c(D, T))
# Simulate lambda_ik(t) using a different covariance matrix for each topic
for (d in 1:D) {
cov_matrix_mu <- exp(-0.5 * var_scales_mu[d] * (time_diff ^ 2) / length_scales_mu[d] ^
2)
mu_d[d, ] <- mvrnorm(1, mu = rep(logit(0.01), T), Sigma = cov_matrix_mu)
}
par(mfrow = c(1, 1))
matplot(
t(mu_d),
type = 'l',
main = "Disease Prevalence (mu_d)",
xlab = "Time",
ylab = "mu_d"
)
###
# Create lambda,phi matrix
g_i = array(rnorm(num_covariates * N), dim = c(N, num_covariates))
lambda_ik = array(NA, dim = c(N, K, T))
phi_kd = array(NA, dim = c(K, D, T))
Gamma_k = matrix(rnorm(num_covariates * K), nrow = K, ncol = num_covariates)
for (k in 1:K) {
# Simulate lambda_ik(t) using a different covariance matrix for each topic
cov_matrix <- exp(-0.5 * var_scales_lambda[k] * (time_diff ^ 2) / length_scales_lambda[k] ^
2)
image(cov_matrix)
for (i in 1:N) {
mean_lambda = g_i[i, ] %*% Gamma_k[k, ]
# lambda_ik[i, k, ] <- log(1 + exp(mvrnorm(
#   1, mu = rep(mean_lambda, T), Sigma = cov_matrix
# )))  # Ensure positivity
lambda_ik[i, k, ] <- mvrnorm(
1, mu = rep(mean_lambda, T), Sigma = cov_matrix
)
}
}
softmax=function(x){
return(exp(x)/sum(exp(x)))
}
s=apply(lambda_ik,c(1,3),function(x){softmax(x)})
#max_lambda=10
#lambda_ik[lambda_ik>max_lambda]=max_lambda
par(mfrow = c(2, 2))
for (i in sample(1:N, 4)) {
matplot(
t(s[,1 , ]),
type = 'l',
main = paste("Lambda for individual", i),
xlab = "Time",
ylab = "Lambda"
)
}
for (k in 1:K) {
# Simulate lambda_ik(t) using a different covariance matrix for each topic
cov_matrix <- exp(-0.5 * var_scales_phi[k] * (time_diff ^ 2) / length_scales_phi[k] ^
2)
#image(cov_matrix)
for (d in 1:D) {
phi_kd[k, d, ] <- mvrnorm(1, mu = mu_d[d,], Sigma = cov_matrix)
}
image(phi_kd[k,,])
}
mean(phi_kd)
eta=plogis(phi_kd)
head(eta)
mean(eta)
par(mfrow = c(2, 2))
for (d in 1:D) {
matplot(
t(phi_kd[, d, ]),
main = paste("Phi for disease", d),
xlab = "Time",
ylab = "Phi"
)
}
par(mfrow = c(2, 2))
for (k in 1:K) {
matplot(
t(phi_kd[k, , ]),
main = paste("Phi for topic", k),
xlab = "Time",
ylab = "Phi"
)
}
###
library(einsum)
pi <- einsum('knt,kdt->ndt', s, eta)
N <- dim(pi)[1]
D <- dim(pi)[2]
T <- dim(pi)[3]
# Create an array to store the results
Y <- array(0, dim = c(N, D, T))
# Fill the array with Bernoulli draws
Y[] <- rbinom(n = N*D*T, size = 1, prob = c(pi))
sum(Y)
mean(pi)
length(Y)
pi*length(Y)
pi
mean(pi)*length(Y)
mean(pi)
length(Y)
sum(Y)
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
sum(Y)
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
sum(Y)
mean(pi)
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
mean(pi)
sum(Y)
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
sum(Y)
precompute_likelihood_indices <- function(Y) {
n_individuals <- dim(Y)[1]
n_diseases <- dim(Y)[2]
Ttot <- dim(Y)[3]
# Initialize lists to store indices
event_indices <- list()
at_risk_indices <- list()
for (i in 1:n_individuals) {
for (d in 1:n_diseases) {
event_time <- which(Y[i, d, ] == 1)
if (length(event_time) > 0) {
event_indices <- c(event_indices, list(c(i, d, event_time)))
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:(event_time-1))))
} else {
# If no event, consider at risk for all time points
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:Ttot)))
}
}
}
list(event_indices = do.call(rbind, event_indices),
at_risk_indices = do.call(rbind, at_risk_indices))
}
a=precompute_likelihood_indices(Y)
warnings()
dim(Y)
event_time=array(0,dim(Y))
precompute_likelihood_indices <- function(Y) {
n_individuals <- dim(Y)[1]
n_diseases <- dim(Y)[2]
Ttot <- dim(Y)[3]
# Initialize lists to store indices
event_indices <- list()
at_risk_indices <- list()
for (i in 1:n_individuals) {
for (d in 1:n_diseases) {
event_time <- which(Y[i, d, ] == 1)
if (length(event_time) > 0) {
event_indices <- c(event_indices, list(c(i, d, event_time)))
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:(event_time-1))))
} else {
# If no event, consider at risk for all time points
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:Ttot)))
}
}
}
list(event_indices = do.call(rbind, event_indices),
at_risk_indices = do.call(rbind, at_risk_indices))
}
event_time=array(0,dim(Y))
event_time=which(Y==1)
precompute_likelihood_indices <- function(Y) {
n_individuals <- dim(Y)[1]
n_diseases <- dim(Y)[2]
Ttot <- dim(Y)[3]
# Initialize lists to store indices
event_indices <- list()
at_risk_indices <- list()
for (i in 1:n_individuals) {
for (d in 1:n_diseases) {
event_time <- which(Y[i, d, ] == 1)
if (length(event_time) > 0) {
event_indices <- c(event_indices, list(c(i, d, event_time)))
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:(event_time-1))))
} else {
# If no event, consider at risk for all time points
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:Ttot)))
}
}
}
list(event_indices = do.call(rbind, event_indices),
at_risk_indices = do.call(rbind, at_risk_indices))
}
precompute_likelihood_indices(Y)
warnings()
apply(y,c(1,2),sum)
a=apply(y,c(1,2),sum)
dim(a)
sum(a>1)
precompute_likelihood_indices <- function(Y) {
n_individuals <- dim(Y)[1]
n_diseases <- dim(Y)[2]
Ttot <- dim(Y)[3]
# Initialize lists to store indices
event_indices <- list()
at_risk_indices <- list()
for (i in 1:n_individuals) {
for (d in 1:n_diseases) {
event_time <- which(Y[i, d, ] == 1)[1]  # Take only the first (and only) event time
if (!is.na(event_time)) {
# Add the event time
event_indices <- c(event_indices, list(c(i, d, event_time)))
# Add at-risk times up to the event
if (event_time > 1) {
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:(event_time-1))))
}
} else {
# If no event, consider at risk for all time points
at_risk_indices <- c(at_risk_indices, list(cbind(i, d, 1:Ttot)))
}
}
}
list(event_indices = do.call(rbind, event_indices),
at_risk_indices = do.call(rbind, at_risk_indices))
}
precompute_likelihood_indices(Y)
a=precompute_likelihood_indices(Y)
dim(a)
a$event_indices
a$event_indices[1]
a$event_indices[1:10,]
dim(a)
dim(a$event_indices)
y[1,2,48]
Y[1,2,48]
Y[6,2,16]
head(a$at_risk_indices)
Lambda=lambda_ik
Phi=phi_kd
head(a)
precomputed_indices=a
n_individuals <- dim(Lambda)[1]
n_topics <- dim(Lambda)[2]
n_diseases <- dim(Phi)[2]
Ttot <- dim(Lambda)[3]
theta <- apply_softmax_to_lambda(Lambda)
eta <- plogis(Phi)  # logistic function
pi <- einsum::einsum("nkt,kdt->ndt", theta, eta)
event_indices <- precomputed_indices$event_indices
at_risk_indices <- precomputed_indices$at_risk_indices
precomputed_indices$at_risk_indices[10,]
precomputed_indices$event_indices[10,]
Y[7,2,47]
log_lik <- 0
# Handle events, including those at time 1
if (nrow(event_indices) > 0) {
log_lik <- log_lik + sum(log(pi[event_indices]))
}
# Handle at-risk periods
if (nrow(at_risk_indices) > 0) {
log_lik <- log_lik + sum(log(1 - pi[at_risk_indices]))
}
dim(pi)
pi[event_indices]
pi[event_indices]
pi[event_indices][1:10]
event_indices[1:10,]
pi[1,2,48]
pi[1,3,21]
pi[2,2,23]
# Updated log-likelihood function
compute_log_likelihood <- function(Lambda, Phi, precomputed_indices) {
n_individuals <- dim(Lambda)[1]
n_topics <- dim(Lambda)[2]
n_diseases <- dim(Phi)[2]
Ttot <- dim(Lambda)[3]
theta <- apply_softmax_to_lambda(Lambda)
eta <- plogis(Phi)  # logistic function
pi <- einsum::einsum("nkt,kdt->ndt", theta, eta)
event_indices <- precomputed_indices$event_indices
at_risk_indices <- precomputed_indices$at_risk_indices
log_lik <- 0
# Handle events, including those at time 1
if (nrow(event_indices) > 0) {
log_lik <- log_lik + sum(log(pi[event_indices]))
}
# Handle at-risk periods
if (nrow(at_risk_indices) > 0) {
log_lik <- log_lik + sum(log(1 - pi[at_risk_indices]))
}
return(log_lik)
}
old=compute_log_likelihood(Lambda = Lambda,Phi=Phi,precomputed_indices = precomputed_indices)
older=log_likelihood(Y,Lambda = Lambda,Phi=Phi)
old
older
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
?Toeplitz
time_points <- 1:50
# Define kernel hyperparameters
length_scale <- 10
variance <- 1
jitter <- 1e-6  # Small jitter term to improve conditioning
# Compute the first row of the Toeplitz matrix
first_row <- sapply(time_points, function(t)
rbf_kernel(time_points[1], t, length_scale, variance))
head(first_row)
first_row
# Add jitter to the diagonal to improve stability
K <- K + diag(jitter, nrow(K))
K <- toeplitz(first_row)
image(K)
library(mvtnorm)
library(MASS)
library(pracma)
library(reshape2)
library(dplyr)
library(einsum)
set.seed(123)
# Create time differences matrix
time_diff <- outer(seq_len(T), seq_len(T), "-")
# Generate scales
length_scales_lambda <- runif(K, T / 3, T / 2)
var_scales_lambda <- runif(K, 0.8, 1.2)
length_scales_phi <- runif(K, T / 3, T / 2)
var_scales_phi <- runif(K, 0.8, 1.2)
length_scales_mu <- runif(D, T / 3, T / 2)
var_scales_mu <- runif(D, 0.8, 1.2)
mu_d <- array(NA, dim = c(D, T))
for (d in 1:D) {
cov_matrix_mu <- exp(-0.5 * var_scales_mu[d] * (time_diff ^ 2) / length_scales_mu[d] ^ 2)
mu_d[d, ] <- mvrnorm(1, mu = rep(qlogis(0.01), T), Sigma = cov_matrix_mu)
}
head(mu_d)
# Generate lambda, phi matrices
g_i <- array(rnorm(num_covariates * N), dim = c(N, num_covariates))
lambda_ik <- array(NA, dim = c(N, K, T))
phi_kd <- array(NA, dim = c(K, D, T))
Gamma_k <- matrix(rnorm(num_covariates * K), nrow = K, ncol = num_covariates)
K=3
# Generate lambda, phi matrices
g_i <- array(rnorm(num_covariates * N), dim = c(N, num_covariates))
lambda_ik <- array(NA, dim = c(N, K, T))
phi_kd <- array(NA, dim = c(K, D, T))
Gamma_k <- matrix(rnorm(num_covariates * K), nrow = K, ncol = num_covariates)
head(phi_kd)
# Simulate lambda
for (k in 1:K) {
cov_matrix <- exp(-0.5 * var_scales_lambda[k] * (time_diff ^ 2) / length_scales_lambda[k] ^ 2)
for (i in 1:N) {
mean_lambda <- g_i[i, ] %*% Gamma_k[k, ]
lambda_ik[i, k, ] <- mvrnorm(1, mu = rep(mean_lambda, T), Sigma = cov_matrix)
}
}
# Apply softmax to lambda
s <- apply(lambda_ik, c(1,3), function(x) exp(x) / sum(exp(x)))
s <- aperm(s, c(2,1,3))  # Reorder dimensions to match original lambda_ik
# Simulate phi
for (k in 1:K) {
cov_matrix <- exp(-0.5 * var_scales_phi[k] * (time_diff ^ 2) / length_scales_phi[k] ^ 2)
for (d in 1:D) {
phi_kd[k, d, ] <- mvrnorm(1, mu = mu_d[d,], Sigma = cov_matrix)
}
}
eta <- plogis(phi_kd)
head(eta)
head(phi_kd)
dim(s)
dim(dim(eta))
dim(eta)
pi <- einsum('nkt,kdt->ndt', s, eta)
pi <- einsum('nkt,kdt->ndt', s, eta)
Y <- array(rbinom(n = N*D*T, size = 1, prob = pi), dim = c(N, D, T))
head(pi)
head(Y)
image(pi)
image(pi)
image(pi[1,,])
pi <- einsum('nkt,kdt->ndt', s, eta)
Y <- array(rbinom(n = N*D*T, size = 1, prob = pi), dim = c(N, D, T))
# Return all generated data and parameters
return(list(
Y = Y,
G = g_i,
var_scales_lambda = var_scales_lambda,
length_scales_lambda = length_scales_lambda,
var_scales_phi = var_scales_phi,
length_scales_phi = length_scales_phi,
var_scales_mu = var_scales_mu,
length_scales_mu = length_scales_mu,
mu_d = mu_d,
lambda_ik = lambda_ik,
phi_kd = phi_kd,
Gamma_k = Gamma_k,
pi = pi,
s = s,
eta = eta
))
# Apply softmax to lambda
theta <- apply(lambda_ik, c(1,3), function(x) exp(x) / sum(exp(x)))
theta <- aperm(s, c(2,1,3))  # Reorder dimensions to match original lambda_ik
dim(theta)
# Apply softmax to lambda
theta <- apply(lambda_ik, c(1,3), function(x) exp(x) / sum(exp(x)))
theta <- aperm(s, c(2,1,3))  # Reorder dimensions to match original lambda_ik
dim(theta)
theta <- apply(lambda_ik, c(1,3), function(x) exp(x) / sum(exp(x)))
dim(theta)
theta <- apply(lambda_ik, c(1,3), function(x) exp(x) / sum(exp(x)))
theta <- aperm(theta, c(2,1,3))  # Reorder dimensions to match original lambda_ik
dim(theta)
sum(theta[1,,1])
head(pi)
head(pi[1,,1])
theta[1,,1]%*%phi_kd[1,,1]
theta[1,,1]%*%phi_kd[,1,1]
theta[1,,1]%*%phi_kd[,,1]
theta[1,,1]%*%eta[,,1]
pi[1,,1]
source("simulations/simwithlogit.R")
source("mcmc_with_elliptical.R")
source("mcmc_sampler.R")
source("utils/utils.R")
source("utils/model_functions.R")
source("utils/sampling_methods.R")
source("utils/initialization.R")
log_gp_prior_vec()
log_gp_prior_vec
log_gp_prior_vec(
Lambda[i, k, ],
rep(g_i[i, ] %*% Gamma[k, ], T),
K_inv_lambda[[k]]$K_inv,
K_inv_lambda[[k]]$log_det_K
)
Lambda=lambda_ik
Gamma=Gamma_k
n_topics
pi_values=pi
pi=base::pi
K_inv_lambda <- lapply(1:3, function(k)
precompute_K_inv(
T,
length_scales_lambda[k],
var_scales_lambda[k]
))
K_inv_lambda
K_inv_lambda[[1]]$log_det_K
str(K_inv_lambda[[1]]$log_det_K)
as.numeric(K_inv_lambda[[1]]$log_det_K)
source("~/aladynoulli/Rscripts/simulations/simwithlogit.R")
inc=readRDS("~/Desktop/disease_array_incidence.rds")
mean(inc)
head(inc)
dim(inc)
sum(inc)
mean(inc)
dimnames(inc)
apply(inc,c(1,3),mean)
apply(inc,c(2,3),mean)
a=apply(inc,c(2,3),mean)
head(a)
image(a)
heatmap(a)
matplot(a[sample(nrow(a),])
matplot(a[sample(nrow(a),])
matplot(a[sample(nrow(a),])
a[sample(nrow(a),]
matplot(a[sample(nrow(a),])
matplot(a[sample(nrow(a),])
library(ATM::HES_age_example)
ATM::HES_age_example
head(ATM::HES_age_example)
length(unique(ATM::HES_age_example))
length(unique(ATM::HES_age_example$eid))
min(unique(ATM::HES_age_example$age_diag))
max(unique(ATM::HES_age_example$age_diag))
